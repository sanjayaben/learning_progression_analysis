# learning_progression_analysis
### Project Motivation
Objective of the project is to analyse the student progression based on existing data from student interactions and then build a predictive models to determine if a given group of students can succeed in completing a given task. The project used a data set made available for the [KDD Cup 2010](https://pslcdatashop.web.cmu.edu/KDDCup/rules.jsp) to analyze and develop the models. The data was derived from log files of an intelligent tutoring system designed to teach mathematics. The work done in this project focussed on achieving following objectives. Entire analysis was carried out adhering to the [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining) approach
1. Understand interesting problems to be solved in the education context using a dataset of this nature. Being able to understand student progression over time and being able to predict the outcomes provide greater oppotunities to educators and parents to make timely interventions in the student's learning pathways.
2. Analyze the dataset to understand the trends. This type of a dataset can provide interesting insights on the type of coverage the education platform provides and the areas of the curriculum the students struggle. Being able to visualize the learning progression and identifying those who are heading towards mastery was also an inetersting outcome.
3. Transform the available data into formats useful for decision making was an interesting challenge. The temporal element is significant in this problem given that the student's proficiency varies overtime. Factoring this into the feature engineering exercise was important and somewhat complicated at the same time.
4. Training machine learning models to predict the the student's success was the final outcome expected. Given the need of a binary classification, three algorithms were tried 1. Logistic Regression 2. SVM 3. KNN.  


### Installation
The code found in this repo should be used with Python versions 3.X. The main packages that needs installation are,
1. [pandas](https://pandas.pydata.org/)
2. [plotly](https://plotly.com/python/getting-started/)
3. [seaborn](https://seaborn.pydata.org/)
4. [sklearn](https://scikit-learn.org/stable/)

Please note that the input dataset is zipped to meet the size restrictions and it is important to unzip data/input/algebra_2005_2006_train.txt.zip before continuing. Also note that there are some other files that would be generated by the data preparation scripts and these files would be created in the data/output folder. Each file contains a __main__ that you can execute to retrieve the required output but the order of the functions is important given that one function may depend on data generated by another function. The execution of the data preparation script is mandatory since it creates some data files required by exploration and modeling steps.
The data folder contain python scripts related to data loading, preparation and visualization. The model folder contains scripts used for feature engineering and machine learning.

Files included are,
1. data/input/algebra_2005_2006_train.txt.zip - the training data set. Please unzip the file in the same location before proceeding
2. data/preparation.py - loads the data and transform into few different formats useful for analysis
3. data/exploration.py - contains the functions used analysing the data. Most functions provide some form of a visualisation. 
4. model/feature_engineering.py - include functions used for selecting features, engineering new features, removing NaNs and scalling features
5. model/modelling.py - contains functions used for training and evaluating predictive models

Note: the training dataset contains around 800k + records and hence some of the preparation and model training functions may take considerable amount of time. 


### Results
See following [blog post]() for in depth analysis of the process and results.
In general following are a summary of the observations and outcomes.
1. The data analysis clearly shows that not all Knowledge Components (KCs) are addressed equally by the tutoring system.
2. In general students seems to struggle with specific areas of the curriculum. 
3. Student's progression analysis is a good way to identify students achieving mastery. 
4. The avegrage time spent on a problem and the mean first attempt success rates are good indicators of the difficulty of a problem.
5. Out of the algorithms tried, only logistic regression converges in a reasonable timeframe with the default paramaters.It provides an accuracy rate of 0.9078 and with some hyperparameter tuning with GridSearchCV we can improve the accuracy to 0.94626

### Future work
Student pathway analysis can create a solid foundation for building reactive systems that can observe successful pathways and recommend these for students who are similar in ability. 

### Licensing, Authors, Acknowledgements
Credit should goto PSLC Data shop for hosting the [dataset](https://pslcdatashop.web.cmu.edu/KDDCup/rules.jsp) and Udacity for recommending. 
